## /////////////////////////////////////// BEGIN Jaeger
# I generated it using
# curl https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/examples/simplest.yaml | docker run -i --rm jaegertracing/jaeger-operator:master generate | kubectl apply -n jaeger -f -
apiVersion: v1
kind: Namespace
metadata:
  name: jaeger
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: jaeger
  name: simplest
  namespace: jaeger

---
apiVersion: v1
data:
  sampling: '{"default_strategy":{"param":1,"type":"probabilistic"}}'
kind: ConfigMap
metadata:
  labels:
    app: jaeger
  name: simplest-sampling-configuration
  namespace: jaeger
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "false"
    service.beta.openshift.io/serving-cert-secret-name: simplest-collector-headless-tls
  labels:
    app: jaeger
  name: simplest-collector-headless
  namespace: jaeger
spec:
  clusterIP: None
  ports:
  - name: http-zipkin
    port: 9411
  - name: grpc-http
    port: 14250
  - name: c-tchan-trft
    port: 14267
  - name: http-c-binary-trft
    port: 14268
  selector:
    app: jaeger
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: jaeger
  name: simplest-collector
  namespace: jaeger
spec:
  ports:
  - name: http-zipkin
    port: 9411
  - name: grpc-http
    port: 14250
  - name: c-tchan-trft
    port: 14267
  - name: http-c-binary-trft
    port: 14268
  selector:
    app: jaeger
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: jaeger
  name: simplest-query
  namespace: jaeger
spec:
  type: NodePort
  ports:
  - name: http-query
    port: 16686
    targetPort: 16686
  selector:
    app: jaeger
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: jaeger-ingress
  namespace: jaeger
spec:
  rules:
    - host: jaeger.minikube
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: simplest-query
                port:
                  number: 16686

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: jaeger
  name: simplest-agent
  namespace: jaeger
spec:
  clusterIP: None
  ports:
  - name: zk-compact-trft
    port: 5775
    protocol: UDP
  - name: config-rest
    port: 5778
  - name: jg-compact-trft
    port: 6831
    protocol: UDP
  - name: jg-binary-trft
    port: 6832
    protocol: UDP
  selector:
    app: jaeger
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    linkerd.io/inject: disabled
    prometheus.io/port: "14269"
    prometheus.io/scrape: "true"
    sidecar.istio.io/inject: "false"
  labels:
    app: jaeger
  name: simplest
  namespace: jaeger
spec:
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      annotations:
        linkerd.io/inject: disabled
        prometheus.io/port: "14269"
        prometheus.io/scrape: "true"
        sidecar.istio.io/inject: "false"
      labels:
        app: jaeger
    spec:
      containers:
      - args:
        - --sampling.strategies-file=/etc/jaeger/sampling/sampling.json
        env:
        - name: SPAN_STORAGE_TYPE
          value: memory
        - name: COLLECTOR_ZIPKIN_HOST_PORT
          value: :9411
        - name: JAEGER_DISABLED
          value: "false"
        image: jaegertracing/all-in-one:1.22.0
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /
            port: 14269
          initialDelaySeconds: 5
          periodSeconds: 15
        name: jaeger
        ports:
        - containerPort: 5775
          name: zk-compact-trft
          protocol: UDP
        - containerPort: 5778
          name: config-rest
        - containerPort: 6831
          name: jg-compact-trft
          protocol: UDP
        - containerPort: 6832
          name: jg-binary-trft
          protocol: UDP
        - containerPort: 9411
          name: zipkin
        - containerPort: 14267
          name: c-tchan-trft
        - containerPort: 14268
          name: c-binary-trft
        - containerPort: 16686
          name: query
        - containerPort: 14269
          name: admin-http
        - containerPort: 14250
          name: grpc
        readinessProbe:
          httpGet:
            path: /
            port: 14269
          initialDelaySeconds: 1
        volumeMounts:
        - mountPath: /etc/jaeger/sampling
          name: simplest-sampling-configuration-volume
          readOnly: true
      enableServiceLinks: false
      serviceAccountName: simplest
      volumes:
      - configMap:
          items:
          - key: sampling
            path: sampling.json
          name: simplest-sampling-configuration
        name: simplest-sampling-configuration-volume
---
## /////////////////////////////////////// BEGIN Zipkin
apiVersion: v1
kind: Namespace
metadata:
  name: zipkin
---

apiVersion: v1
kind: Service
metadata:
  labels:
    app: zipkin
  name: zipkin
  namespace: zipkin
spec:
  type: NodePort
  ports:
  - port: 9411
    protocol: TCP
    targetPort: 9411
  selector:
    app: zipkin
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: zipkin-ingress
  namespace: zipkin
spec:
  rules:
    - host: zipkin.minikube
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: zipkin
                port:
                  number: 9411

---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: zipkin
  name: zipkin
  namespace: zipkin
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zipkin
  template:
    metadata:
      labels:
        app: zipkin
    spec:
      containers:
      - image: openzipkin/zipkin:2.23.2
        imagePullPolicy: Always
        name: zipkin
        env:
        - name: JAVA_OPTS
          value: "-Dlogging.level.zipkin=DEBUG -Dlogging.level.zipkin2=DEBUG"

## /////////////////////////////////////// END Zipkin

---
## /////////////////////////////////////// BEGIN OTEL collector
apiVersion: v1
kind: Namespace
metadata:
  name: otel
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-agent-conf
  namespace: otel
  labels:
    app: opentelemetry
    component: otel-agent-conf
data:
  otel-agent-config: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
    exporters:
      otlp:
        endpoint: "otel-collector.default.svc.cluster.local:55680" # TODO: Update me 
        insecure: true
        sending_queue:
          num_consumers: 4
          queue_size: 100
        retry_on_failure:
          enabled: true
    processors:
      batch:
      memory_limiter:
        # Same as --mem-ballast-size-mib CLI argument
        ballast_size_mib: 165
        # 80% of maximum memory up to 2G
        limit_mib: 400
        # 25% of limit up to 2G
        spike_limit_mib: 100
        check_interval: 5s
    extensions:
      health_check: {}
      zpages: {}
    service:
      extensions: [health_check, zpages]
      pipelines:
        traces:
          receivers: [otlp]
          processors: []
          exporters: [otlp]
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-agent
  namespace: otel
  labels:
    app: opentelemetry
    component: otel-agent
spec:
  selector:
    matchLabels:
      app: opentelemetry
      component: otel-agent
  template:
    metadata:
      labels:
        app: opentelemetry
        component: otel-agent
    spec:
      containers:
      - command:
          - "/otelcontribcol"
          - "--config=/conf/otel-agent-config.yaml"
          # Memory Ballast size should be max 1/3 to 1/2 of memory.
          - "--mem-ballast-size-mib=165"
        image: otel/opentelemetry-collector-contrib:0.27.0
        name: otel-agent
        resources:
          limits:
            cpu: 500m
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 55679 # ZPages endpoint.
        - containerPort: 55680 # Default OpenTelemetry receiver port.
        - containerPort: 8888  # Metrics.
        volumeMounts:
        - name: otel-agent-config-vol
          mountPath: /conf
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
      volumes:
        - configMap:
            name: otel-agent-conf
            items:
              - key: otel-agent-config
                path: otel-agent-config.yaml
          name: otel-agent-config-vol
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-conf
  namespace: otel
  labels:
    app: opentelemetry
    component: otel-collector-conf
data:
  otel-collector-config: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
    processors:
      batch:
      memory_limiter:
        # Same as --mem-ballast-size-mib CLI argument
        ballast_size_mib: 683
        # 80% of maximum memory up to 2G
        limit_mib: 1500
        # 25% of limit up to 2G
        spike_limit_mib: 512
        check_interval: 5s
    extensions:
      health_check: {}
      zpages: {}
    exporters:
      zipkin:
        endpoint: "http://zipkin.zipkin.svc.cluster.local:9411/api/v2/spans" 
      jaeger:
        endpoint: "simplest-collector.jaeger.svc.cluster.local:14250" 
        insecure: true
      logging:  
    service:
      extensions: [health_check, zpages]
      pipelines:
        traces/1:
          receivers: [otlp]
          processors: []
          exporters: [logging, zipkin, jaeger]
---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: otel
  labels:
    app: opentelemetry
    component: otel-collector
spec:
  type: NodePort
  ports:
  - name: otlp # Default endpoint for OpenTelemetry receiver.
    port: 55680
    protocol: TCP
    targetPort: 55680
  - name: jaeger-grpc # Default endpoint for Jaeger gRPC receiver
    port: 14250
  - name: jaeger-thrift-http # Default endpoint for Jaeger HTTP receiver.
    port: 14268
  - name: zipkin # Default endpoint for Zipkin receiver.
    port: 9411
  - name: metrics # Default endpoint for querying metrics.
    port: 8888
  selector:
    component: otel-collector
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: otel
  labels:
    app: opentelemetry
    component: otel-collector
spec:
  selector:
    matchLabels:
      app: opentelemetry
      component: otel-collector
  minReadySeconds: 5
  progressDeadlineSeconds: 120
  replicas: 1 #TODO - adjust this to your own requirements
  template:
    metadata:
      labels:
        app: opentelemetry
        component: otel-collector
    spec:
      containers:
      - command:
          - "/otelcontribcol"
          - "--config=/conf/otel-collector-config.yaml"
#           Memory Ballast size should be max 1/3 to 1/2 of memory.
          - "--mem-ballast-size-mib=683"
          - "--log-level=DEBUG"
        image: otel/opentelemetry-collector-contrib:0.27.0
        name: otel-collector
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 200m
            memory: 400Mi
        ports:
        - containerPort: 55679 # Default endpoint for ZPages.
        - containerPort: 55680 # Default endpoint for OpenTelemetry receiver.
        - containerPort: 14250 # Default endpoint for Jaeger HTTP receiver.
        - containerPort: 14268 # Default endpoint for Jaeger HTTP receiver.
        - containerPort: 9411 # Default endpoint for Zipkin receiver.
        - containerPort: 8888  # Default endpoint for querying metrics.
        volumeMounts:
        - name: otel-collector-config-vol
          mountPath: /conf
#        - name: otel-collector-secrets
#          mountPath: /secrets
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
      volumes:
        - configMap:
            name: otel-collector-conf
            items:
              - key: otel-collector-config
                path: otel-collector-config.yaml
          name: otel-collector-config-vol
#        - secret:
#            name: otel-collector-secrets
#            items:
#              - key: cert.pem
#                path: cert.pem
#              - key: key.pem
#                path: key.pem

## /////////////////////////////////////// END OTEL collector

---
## /////////////////////////////////////// BEGIN hello service

apiVersion: v1
kind: Service
metadata:
  name: hello
spec:
  type: NodePort
  selector:
    app: hello
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
      name: web
    - protocol: TCP
      port: 5678
      targetPort: 5678
      name: debug
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hello-ingress
spec:
  rules:
    - host: hello.minikube
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: hello
                port:
                  number: 8000
---
apiVersion: v1
data:
  entrypoint.sh: |
    #!/bin/bash

    export FLASK_APP=./server.py

    while test $# -gt 0
    do
    case "$1" in
    --none)
    echo "option none"
    python3 -m flask run --host=0.0.0.0 --port=8000

    ;;
    --debug)
    echo "option debug"
    pip3 install --user debugpy
    export PATH=$HOME/.local/bin:$PATH

    python3 -m debugpy --listen 0.0.0.0:5678 -m flask run --host=0.0.0.0 --port=8000
    ;;
    --trace)
    echo "option trace"
    pip3 install --user opentelemetry-api==1.2.0 opentelemetry-sdk==1.2.0 opentelemetry-instrumentation==0.21b0 opentelemetry-distro==0.21b0  opentelemetry-exporter-otlp==1.2.0
    pip3 install --user opentelemetry-instrumentation-flask==0.21b0 opentelemetry-instrumentation-grpc==0.21b0 opentelemetry-instrumentation-jinja2==0.21b0 opentelemetry-instrumentation-requests==0.21b0 opentelemetry-instrumentation-sqlite3==0.21b0 opentelemetry-instrumentation-urllib==0.21b0
    export PATH=$HOME/.local/bin:$PATH

    #exec opentelemetry-bootstrap
    #exec opentelemetry-bootstrap --action=install


    opentelemetry-instrument python3 -m flask run --no-reload --host=0.0.0.0 --port=8000
    ;;
    --*)
    echo "bad option $1"
    ;;
    *) echo "argument $1"
    ;;
    esac
    shift
    done

    exit 0
kind: ConfigMap
metadata:
  name: scripts-config
---  
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: hello
  name: hello
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hello
  template:
    metadata:
      labels:
        app: hello
    spec:
      containers:
      - image: tha2015/helloworld:latest
        name: helloworld3
        imagePullPolicy: Always
        volumeMounts:
          - name: scripts-vol
            mountPath: /scripts
        command: ["/bin/sh", "/scripts/entrypoint.sh", "--trace"]
        env:
        - name: FLASK_APP
          value: "./server.py"

        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name  # pod’s name
        - name: OTEL_TRACES_EXPORTER
          value: "otlp"
        - name: OTEL_METRICS_EXPORTER
          value: "otlp"
        - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
          value: "http://otel-collector.otel.svc.cluster.local:55680" # OR http://192.168.1.200:32637 , NodePort of otel-collector service (for 55680)
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector.otel.svc.cluster.local:55680" # OR http://192.168.1.200:32637 , NodePort of otel-collector service (for 55680)
        - name: OTEL_SERVICE_NAME
          value: "helloworld"
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.version=0.1,service.instance.id=$(POD_NAME)"
      volumes:
        - name: scripts-vol
          configMap:
            name: scripts-config

## /////////////////////////////////////// END hello service

# add to hosts file
#192.168.1.200 zipkin.minikube
#192.168.1.200 zipkin.minikube
